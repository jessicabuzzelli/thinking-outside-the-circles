{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['legacy_system_cd', 'legacy_division_cd', 'legacy_product_cd',\n",
      "       'legacy_product_desc', 'core_item_flag', 'segment', 'PROD_CAT_1_NAME',\n",
      "       'PROD_CAT_2_NAME', 'PROD_CAT_3_NAME', 'PROD_CAT_4_NAME',\n",
      "       'legacy_vendor_cd', 'stocking_flag', 'LEGACY_CUSTOMER_CD',\n",
      "       'saalfeld_customer_flag', 'national_acct_flag', 'ship-to_zip_code',\n",
      "       'sales_channel', 'qty_6mos', 'cogs_6mos', 'Sales_6_mos', 'picks_6mos',\n",
      "       'Margin_%', 'net_OH', 'net_OH_usd', 'pallet_quantity', 'item_poi_days',\n",
      "       'DIOH'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Goal is to find the worst performing products\n",
    "import numpy as np\n",
    "\n",
    "#import dataset\n",
    "import pandas as pd\n",
    "df = pd.read_excel(\"North Central Sales 6 Months GIT v2.xlsx\", sheet_name=\"North Central\")\n",
    "\n",
    "#remove whitespace from column names for easy access\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "df.columns = [c.replace('$', 'usd') for c in df.columns]\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 2038\n",
      "50 0\n",
      "73 145\n",
      "74 85\n",
      "75 2493\n",
      "77 1245\n",
      "78 187\n",
      "81 1785\n",
      "82 1463\n",
      "83 474\n",
      "84 2800\n",
      "85 1454\n",
      "87 1229\n",
      "89 2648\n",
      "41 784\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary that maps:\n",
    "#Warehouse (Division) -> Unique products sold at division\n",
    "\n",
    "warehouses = df.legacy_division_cd.unique()\n",
    "warehouse_to_prod = {}\n",
    "\n",
    "for w in warehouses:\n",
    "    warehouse_to_prod[w] = []\n",
    "\n",
    "for w, p, sc in zip(df.legacy_division_cd.values, df.legacy_product_cd.values, df.sales_channel):\n",
    "    for ware in warehouses:\n",
    "        #WE ARE CHECKING THAT THE SALES CHANNEL IS WAREHOUSE\n",
    "        if w == ware and p not in warehouse_to_prod[w] and sc == \"Warehouse\":\n",
    "            warehouse_to_prod[w].append(p)\n",
    "\n",
    "#Print warehouse to number of individual different products stored            \n",
    "for w in warehouses:\n",
    "    print(w, len(warehouse_to_prod[w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of warehouse & product -> total sales in a 6month period\n",
    "wp_to_sales = {}\n",
    "#Create a dictionary of warehouse & product -> total costs in a 6month period\n",
    "wp_to_costs = {}\n",
    "#Create a dictionary of warehouse & product -> total number of picks in a 6month period\n",
    "wp_to_picks = {}\n",
    "#Create a dictionary of warehouse & product -> total quantity sold in a 6month period\n",
    "wp_to_quantity = {}\n",
    "for w in warehouses:\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        wp_to_sales[w,p] = []\n",
    "        wp_to_costs[w,p] = []\n",
    "        wp_to_picks[w,p] = []\n",
    "        wp_to_quantity[w,p] = []\n",
    "\n",
    "for w, p, s, c, pk, q in zip(df.legacy_division_cd.values, df.legacy_product_cd.values, df.Sales_6_mos, df.cogs_6mos, df.picks_6mos, df.qty_6mos):\n",
    "    if p in warehouse_to_prod[w]:\n",
    "        wp_to_sales[w,p].append(s)\n",
    "        wp_to_costs[w,p].append(c)\n",
    "        wp_to_picks[w,p].append(pk)\n",
    "        wp_to_quantity[w,p].append(q)\n",
    "\n",
    "for w in warehouses:\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        wp_to_sales[w,p] = sum(wp_to_sales[w,p])\n",
    "        wp_to_costs[w,p] = sum(wp_to_costs[w,p])\n",
    "        wp_to_picks[w,p] = sum(wp_to_picks[w,p])\n",
    "        wp_to_quantity[w,p] = sum(wp_to_quantity[w,p])\n",
    "\n",
    "        \n",
    "\n",
    "#Create a dictionary of warehouse & product -> coreflag \"Y\" or \"N\"\n",
    "wp_to_coreflag = {}\n",
    "for w,p,cf in zip(df.legacy_division_cd.values, df.legacy_product_cd.values, df.core_item_flag):\n",
    "    if p in warehouse_to_prod[w]:\n",
    "        if cf == \"Y\":\n",
    "            wp_to_coreflag[w,p] = 1\n",
    "        if cf == \"N\":\n",
    "            wp_to_coreflag[w,p] = 0\n",
    "\n",
    "\n",
    "#Create a dictionary of warehouse & product -> margin%\n",
    "wp_to_margin = {}\n",
    "for w in warehouses:\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        s = wp_to_sales[w,p]\n",
    "        c = wp_to_costs[w,p]\n",
    "        ##DATA HAS TO BE CLEANED SO THAT COSTS THAT ARE EQUAL TO 0 DO NOT EXIST\n",
    "        if c == 0:\n",
    "            wp_to_margin[w,p] = 0\n",
    "        else:\n",
    "            wp_to_margin[w,p] = 100*((s-c)/c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Dictionary of a warehouse, product cd pair with its net OH in units, net OH $ as values, item poi days & DIOH\n",
    "#Example:\n",
    "#Warehouse 19 houses product 10012415 and it has 4 units in on hand inventory, $81.2 of on hand inventory,\n",
    "#302.430555555556 of average poi in days & 38.5263664820611 of DIOH\n",
    "#The dictionary will look like this: wp_to_oh[19, 10012415] = [4.0, 81.2, 302.430555555556, 38.5263664820611]\n",
    "wp_to_stats = {}\n",
    "for w in warehouses:\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        wp_to_stats[w,p] = [0,0,0,0]\n",
    "\n",
    "for w, p, oh_usd, oh, poi, DIOH in zip(df.legacy_division_cd.values, df.legacy_product_cd.values, df.net_OH_usd.values, df.net_OH.values,\n",
    "                           df.item_poi_days.values, df.DIOH.values):\n",
    "    if p in warehouse_to_prod[w]:\n",
    "        if wp_to_stats[w,p] == [0,0,0,0]:\n",
    "            wp_to_stats[w,p] = [oh, oh_usd, poi, DIOH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Dictionary of warehouse & product to turn and earn\n",
    "wp_to_TE = {}\n",
    "for w in warehouses:\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        #netOH in quantity\n",
    "        net_oh = wp_to_stats[w,p][0]\n",
    "        #cost of goods sold\n",
    "        cogs = wp_to_costs[w,p]\n",
    "        #quantity sold\n",
    "        q = wp_to_quantity[w,p]\n",
    "        #margin percentage\n",
    "        mp = wp_to_margin[w,p]\n",
    "        \n",
    "        #DATA MUST BE CLEANED THERE ARE 34 WAREHOUSE & PROD COMBINATIONS THAT \n",
    "        #PRODUCE A DENOMINATOR OF 0 IN THE TURN CALCULATION\n",
    "        if 2*net_oh + q == 0:\n",
    "            wp_to_TE[w,p] = 0\n",
    "        else:\n",
    "            turn = (2*cogs/(2*net_oh + q))\n",
    "            wp_to_TE[w,p] = turn * mp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18529\n",
      "18529\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary of warehouse & prod to score\n",
    "wp_to_score = {}\n",
    "#input of weight of importance of turn and earn\n",
    "w1 = 0.5\n",
    "#input of weight of importance of number of picks\n",
    "w2 = 0.5\n",
    "for w in warehouses:\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        wp_to_score[w,p] = w1*wp_to_TE[w,p]*w2*wp_to_picks[w,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage similarity:  44.330508931944514\n"
     ]
    }
   ],
   "source": [
    "#MODEL THAT ASSINGS cutoff% OF WORSE WAREHOUSE & PRODUCT COMBINATIONS IN THE NORTH CENTRAL REGION AS NON CORE\n",
    "#sort the keys in ascending order by score\n",
    "keys_by_score = sorted(wp_to_score, key=wp_to_score.__getitem__)\n",
    "\n",
    "#input of percentage cut off for core item\n",
    "#what bottom percentage of scores should we remove?\n",
    "cutoff = 0.2\n",
    "\n",
    "cutoffIdx = int(len(keys_by_score)*cutoff)\n",
    "#the bottom cutoff% of the warehouse & product combination sorted by \n",
    "non_core = keys_by_score[:cutoffIdx]\n",
    "core = keys_by_score[cutoffIdx:]\n",
    "\n",
    "#Create our core flag rating dictionary\n",
    "wp_to_ourcore = {}\n",
    "for w,p in non_core:\n",
    "    wp_to_ourcore[w,p] = 0\n",
    "\n",
    "for w,p in core:\n",
    "    wp_to_ourcore[w,p] = 1\n",
    "\n",
    "#percentage similarity in our core flag and Veritiv\n",
    "num_same = 0\n",
    "for w in warehouses:\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        if wp_to_ourcore[w,p] == wp_to_coreflag[w,p]:\n",
    "            num_same += 1\n",
    "similarity = num_same / len(wp_to_ourcore.values())\n",
    "print(\"Percentage similarity: \", similarity*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage similarity:  48.16234011549463\n"
     ]
    }
   ],
   "source": [
    "#MODEL THAT REMOVES cutoff% OF WORSE PRODUCTS AT THE WAREHOUSE LEVEL IN THE NORTH CENTRAL REGION AS NON CORE\n",
    "\n",
    "#Create a dictionary of our core flag rating\n",
    "wp_to_ourcore2 = {}\n",
    "#input of cutoff point\n",
    "cutoff = 0.2\n",
    "#Sort each of the products in a warehouse by their score\n",
    "for w in warehouses:\n",
    "    prod_to_score = {}\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        prod_to_score[p] = wp_to_score[w,p]\n",
    "    #sort products inside of a warehouse by their score in ascending order\n",
    "    prods_by_score = sorted(prod_to_score, key=prod_to_score.__getitem__)\n",
    "    cutoffIdx = int(len(prods_by_score)*cutoff)\n",
    "    #the bottom cutoff% of the warehouse & product combination sorted by \n",
    "    non_core_prods = prods_by_score[:cutoffIdx]\n",
    "    core_prods = prods_by_score[cutoffIdx:]\n",
    "    for p in non_core_prods:\n",
    "        wp_to_ourcore2[w,p] = 0\n",
    "    for p in core_prods:\n",
    "        wp_to_ourcore2[w,p] = 1\n",
    "#percentage similarity in our core flag and Veritiv\n",
    "num_same = 0\n",
    "for w in warehouses:\n",
    "    for p in warehouse_to_prod[w]:\n",
    "        if wp_to_ourcore2[w,p] == wp_to_coreflag[w,p]:\n",
    "            num_same += 1\n",
    "similarity = num_same / len(wp_to_ourcore2.values())\n",
    "print(\"Percentage similarity: \", similarity*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
